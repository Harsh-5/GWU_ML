{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jphall663/GWU_ML/blob/main/notebook/lecture_8/Assignment_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvt2EhcNamhm"
      },
      "source": [
        "# MNIST Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Imports"
      ],
      "metadata": {
        "id": "-Lzerk-SbfmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras # overall package API for deep learning\n",
        "\n",
        "# for data loading/prep\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# for training\n",
        "from keras.models import Sequential # for building sequential, not recurrent, networks\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense # for the components of a lenet5-like network"
      ],
      "metadata": {
        "id": "tm_GcmscbT9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Try for reproducibility"
      ],
      "metadata": {
        "id": "aIy6L5Wyj61Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!PYTHONHASHSEED=0"
      ],
      "metadata": {
        "id": "Th0bp1ehj9rE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random as python_random\n",
        "\n",
        "SEED = 12345\n",
        "\n",
        "np.random.seed(SEED)\n",
        "python_random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ],
      "metadata": {
        "id": "2JaLb5UEkG-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Load and format MNIST data"
      ],
      "metadata": {
        "id": "N7b_uvmPbi8J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iqzI6e-amhu"
      },
      "outputs": [],
      "source": [
        "# load data\n",
        "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()\n",
        "\n",
        "# normalize data \n",
        "x_train = x_train/255\n",
        "x_valid = x_valid/255\n",
        "\n",
        "# ensure y's are treated as categories\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_valid = np_utils.to_categorical(y_valid)\n",
        "num_classes = y_train.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Examine data"
      ],
      "metadata": {
        "id": "wRbr2s--cTOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.array2string(x_train[0], max_line_width=150, precision=2)) # pixel intensities for first training image\n",
        "print()\n",
        "print(y_train[0]) # label for first training image"
      ],
      "metadata": {
        "id": "u7TrwHdCcWbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXwuqWrbamhw"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Initialize a sequential Keras model"
      ],
      "metadata": {
        "id": "VlXB4wbme5nW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "X5lU_49Bamhy"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Define a smaller version of Lenet-5 that uses the standard 28x28 MNIST images"
      ],
      "metadata": {
        "id": "7ytM8PHnfKOf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "TCNU40zmamhy"
      },
      "outputs": [],
      "source": [
        "# C1\n",
        "# 1 image in, 6 feature maps out (1 image represented *in each of* the 6 feature maps)\n",
        "# 28 x 28 x 1 inputs\n",
        "# 1 image goes into 6 filters with (1 x 2 x 2 + 1) = 5 weights for 30 total weights in C1 layer\n",
        "# resulting in ((28 - 2 + 0)/1) + 1 = 27 x 27 x 6 output volume\n",
        "model.add(Conv2D(filters=6, kernel_size=(2,2), input_shape=(28,28,1)))\n",
        "\n",
        "# S2\n",
        "# 6 feature maps in, 6 activation maps out\n",
        "# 27 x 27 x 6 input volume \n",
        "# goes into 0 weights in S2 layer\n",
        "# pooling implies kernel size 4, stride 2 and padding of 0.5 b/c of odd input size\n",
        "# resulting in a ((27 - 4 + 1)/2) + 1 = 13 x 13 x 6 output volume\n",
        "model.add(MaxPooling2D(pool_size=2)) \n",
        "model.add(Activation()) # REQUIRES STUDENT INPUT\n",
        "\n",
        "# C3\n",
        "# 6 activation maps in, 16 feature maps out (6 activation maps represented *in each of* the 16 feature maps)\n",
        "# 13 x 13 x 6 input volume\n",
        "# 6 activation maps go into 16 filters with (6 x 5 x 5 + 1) = 151 weights for a total of 2416 weights in C3 layer\n",
        "# resulting in ((13 - 5 + 0)/1) + 1 = 9 x 9 x 16 output volume\n",
        "model.add(Conv2D(filters=16, kernel_size=(5,5)))\n",
        "\n",
        "# S4\n",
        "# 16 feature maps in, 16 activation maps out\n",
        "# 9 x 9 x 16 input volume\n",
        "# goes into 0 weights in S2 layer\n",
        "# pooling implies kernel size 4, stride 2 and padding of 0.5 b/c of odd input size\n",
        "# resulting in (9 - ? + 1)/2) + 1 = ? x ? x 16 output volume\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Activation()) # REQUIRES STUDENT INPUT\n",
        "\n",
        "# C5\n",
        "# 16 activation maps in, 120 feature maps out (16 activation maps represented *in each of* the 120 feature maps)\n",
        "# ? x ? 16 input volume\n",
        "# 16 activation maps go into 120 filters with (16 x ? x ? + 1) = ?7 weights for a total of ? weights in C5 layer\n",
        "# resulting in a  (? - ? + 0)/1) + 1 = 1 x 1 x 120 output volume \n",
        "model.add(Conv2D(filters=120, kernel_size=(?,?))) # REQUIRES STUDENT INPUT\n",
        "\n",
        "# F6\n",
        "# 120 input elements are flattened and connected to ? weights with biases\n",
        "# resulting in a 120 x ? + ? = ? weights in F6 and a ? x 1 x 1 output volume\n",
        "model.add(Flatten())\n",
        "model.add(Dense(?)) # REQUIRES STUDENT INPUT\n",
        "model.add(Activation()) # REQUIRES STUDENT INPUT\n",
        "\n",
        "# Output\n",
        "# each of ? units in F6 feed into 10 softmax output units\n",
        "# there are ? x ? + ? = ? weights in the output layer resulting in a ? x 1 x 1 output volume\n",
        "# output unit with highest output \"probability\" is the prediction for the image\n",
        "model.add(Dense(?)) # REQUIRES STUDENT INPUT\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. View a summary of the model architecture"
      ],
      "metadata": {
        "id": "F-wrQbwKgz7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "nADiLqGhg40-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Precompile model for faster training"
      ],
      "metadata": {
        "id": "SOHpwRpzg87f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zah-mHZdamhz"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Train model"
      ],
      "metadata": {
        "id": "tRAEx-j2hS3l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHaLygfzamh0"
      },
      "outputs": [],
      "source": [
        "# restart and run notebook for reproducible results\n",
        "# running this cell multiple times will result in irreproducible results\n",
        "_ = model.fit(x_train, y_train, epochs=50, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Evaluate model performance on validation data"
      ],
      "metadata": {
        "id": "diOlWRfXiDi9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lW1I2J0samh0"
      },
      "outputs": [],
      "source": [
        "model.evaluate(x_valid, y_valid, batch_size=128)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Assignment_8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}